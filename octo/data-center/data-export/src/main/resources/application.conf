akka {
  actor.provider = "akka.remote.RemoteActorRefProvider"

  remote {

    enabled-transports = ["akka.remote.netty.tcp"]

    netty.tcp {
      hostname = "127.0.0.1"
      port = 2557
      # Sets the send buffer size of the Sockets,
      # set to 0b for platform default
      send-buffer-size = 2560000b

      # Sets the receive buffer size of the Sockets,
      # set to 0b for platform default
      receive-buffer-size = 2560000b

      # Maximum message size the transport will accept, but at least
      # 32000 bytes.
      # Please note that UDP does not support arbitrary large datagrams,
      # so this setting has to be chosen carefully when using UDP.
      # Both send-buffer-size and receive-buffer-size settings has to
      # be adjusted to be able to buffer messages of maximum size.
      maximum-frame-size = 2560000b
    }

    watch-failure-detector {

      # How often keep-alive heartbeat messages should be sent to each connection.
      heartbeat-interval = 4 s

      # Defines the failure detector threshold.
      # A low threshold is prone to generate many wrong suspicions but ensures
      # a quick detection in the event of a real crash. Conversely, a high
      # threshold generates fewer mistakes but needs more time to detect
      # actual crashes.
      threshold = 20.0

      # Minimum standard deviation to use for the normal distribution in
      # AccrualFailureDetector. Too low standard deviation might result in
      # too much sensitivity for sudden, but normal, deviations in heartbeat
      # inter arrival times.
      min-std-deviation = 200 ms

      # Number of potentially lost/delayed heartbeats that will be
      # accepted before considering it to be an anomaly.
      # This margin is important to be able to survive sudden, occasional,
      # pauses in heartbeat arrivals, due to for example garbage collect or
      # network drop.
      acceptable-heartbeat-pause = 30 s

    }
  }

  loggers = ["akka.event.slf4j.Slf4jLogger"]
  loglevel = INFO
  log-config-on-start = on

  extensions = ["com.romix.akka.serialization.kryo.KryoSerializationExtension$"]

  actor {
    default-dispatcher {
      # Throughput defines the number of messages that are processed in a batch
      # before the thread is returned to the pool. Set to 1 for as fair as possible.
      throughput = 50
    }

    debug {
      receive = on
      autoreceive = on
      lifecycle = on
      fsm = on
      event-stream = on
      unhandled = on
      router-misconfiguration = on
    }
  }

  # Serialization
  actor {
    serializers {
      java = "akka.serialization.JavaSerializer"
      # Define kryo serializer
      kryo = "com.romix.akka.serialization.kryo.KryoSerializer"
    }

    serialization-bindings {
      "java.io.Serializable" = kryo
      "scala.Serializable" = kryo
      "scala.Product" = kryo
    }
  }

  # kryo serialization
  actor {
    kryo {

      kryo-custom-serializer-init = "com.sankuai.octo.log.utils.KryoInit"
      # Possibles values for type are: graph or nograph
      # graph supports serialization of object graphs with shared nodes
      # and cyclic references, but this comes at the expense of a small overhead
      # nograph does not support object grpahs with shared nodes, but is usually faster
      type = "nograph"


      # Possible values for idstrategy are:
      # default, explicit, incremental, automatic
      #
      # default - slowest and produces bigger serialized representation. Contains fully-
      # qualified class names (FQCNs) for each class
      #
      # explicit - fast and produces compact serialized representation. Requires that all
      # classes that will be serialized are pre-registered using the "mappings" and "classes"
      # sections. To guarantee that both sender and receiver use the same numeric ids for the same
      # classes it is advised to provide exactly the same entries in the "mappings" section
      #
      # incremental - fast and produces compact serialized representation. Support optional
      # pre-registering of classes using the "mappings" and "classes" sections. If class is
      # not pre-registered, it will be registered dynamically by picking a next available id
      # To guarantee that both sender and receiver use the same numeric ids for the same
      # classes it is advised to pre-register them using at least the "classes" section
      #
      # automatic - Contains fully-qualified class names (FQCNs) for each class that is not
      # pre-registered in the "mappings" and "classes" section

      idstrategy = "automatic"

      # If set, akka uses manifests to put a class name
      # of the top-level object into each message
      use-manifests = false

      # Enable transparent compression of serialized messages
      # accepted values are: off | lz4 | deflate
      compression = lz4

      # Log implicitly registered classes. Useful, if you want to know all classes
      # which are serialized
      implicit-registration-logging = true

      # If enabled, Kryo logs a lot of information about serialization process.
      # Useful for debugging and lowl-level tweaking
      kryo-trace = false

      # If enabled, Kryo uses internally a map detecting shared nodes.
      # This is a preferred mode for big object graphs with a lot of nodes.
      # For small object graphs (e.g. below 10 nodes) set it to false for
      # better performance.
      kryo-reference-map = false

      # Define mappings from a fully qualified class name to a numeric id.
      # Smaller ids lead to smaller sizes of serialized representations.
      #
      # This section is mandatory for idstartegy=explicit
      # This section is optional  for idstartegy=incremental
      # This section is ignored   for idstartegy=default
      #
      # The smallest possible id should start at 20 (or even higher), because
      # ids below it are used by Kryo internally e.g. for built-in Java and
      # Scala types
      mappings {
        # scala 内部类型
        "[B" = 101,
        "scala.collection.immutable.Vector" = 102,
        "scala.collection.immutable.List" = 103,
        "scala.collection.immutable.Set" = 104,
        "scala.collection.immutable.Set$Set1" = 105,
        "scala.collection.immutable.Set$Set2" = 106,
        "scala.collection.immutable.Set$Set3" = 107,
        "scala.collection.immutable.Set$Set4" = 108,
        "scala.collection.immutable.$colon$colon" = 109,
        "scala.collection.immutable.Map" = 110,
        "scala.collection.immutable.Map$Map1" = 111,
        "scala.collection.immutable.Map$Map2" = 112,
        "scala.collection.immutable.Map$Map3" = 113,
        "scala.collection.immutable.Map$Map4" = 114,
        "scala.Some" = 115,
        "scala.Enumeration$Val" = 116,
        "scala.Enumeration$Value" = 117,


        # akka 类型
        "akka.actor.LocalActorRef" = 201,
        "akka.actor.Identify" = 202,
        "akka.actor.ActorIdentity" = 203,
        "akka.actor.Address" = 204,
        "akka.actor.RepointableActorRef" = 205,
        "akka.dispatch.sysmsg.Watch" = 206,


        # akka remote类型
        "akka.remote.RemoteActorRef" = 301,
        "akka.remote.RemoteWatcher$Heartbeat$" = 302,
        "akka.remote.RemoteWatcher$HeartbeatRsp" = 303,

        # 应用内部类型
        "com.sankuai.octo.statistic.domain.TimeStatus" = 601,
        "com.sankuai.octo.statistic.domain.MetricKey2" = 602,
        "com.sankuai.octo.statistic.domain.MetricData2" = 603,
        "com.sankuai.octo.statistic.domain.Metric2" = 604,
        "com.sankuai.octo.statistic.domain.Metrics" = 605,
        "com.sankuai.octo.statistic.model.StatSource" = 606,
        "com.sankuai.octo.statistic.model.PerfProtocolType" = 607,
        "com.meituan.mtrace.thrift.model.StatusCode" = 608,
      }

      # Define a set of fully qualified class names for
      # classes to be used for serialization.
      # The ids for those classes will be assigned automatically,
      # but respecting the order of declaration in this section
      #
      # This section is optional  for idstartegy=incremental
      # This section is ignored   for idstartegy=default
      # This section is optional  for idstartegy=explicit
      classes = [
        # scala 内部类型
        "[B",
        "scala.collection.immutable.Vector",
        "scala.collection.immutable.List",
        "scala.collection.immutable.Set",
        "scala.collection.immutable.Set$Set1",
        "scala.collection.immutable.Set$Set2",
        "scala.collection.immutable.Set$Set3",
        "scala.collection.immutable.Set$Set4",
        "scala.collection.immutable.$colon$colon",
        "scala.collection.immutable.Map",
        "scala.collection.immutable.Map$Map1",
        "scala.collection.immutable.Map$Map2",
        "scala.collection.immutable.Map$Map3",
        "scala.collection.immutable.Map$Map4",
        "scala.Some",
        "scala.Enumeration$Val",
        "scala.Enumeration$Value",


        # akka 类型
        "akka.actor.LocalActorRef",
        "akka.actor.Identify",
        "akka.actor.ActorIdentity",
        "akka.actor.Address",
        "akka.actor.RepointableActorRef",
        "akka.dispatch.sysmsg.Watch",


        # akka remote类型
        "akka.remote.RemoteActorRef",
        "akka.remote.RemoteWatcher$Heartbeat$",
        "akka.remote.RemoteWatcher$HeartbeatRsp"

        # 应用内部类型
        "com.sankuai.octo.statistic.domain.TimeStatus",
        "com.sankuai.octo.statistic.domain.MetricKey2",
        "com.sankuai.octo.statistic.domain.MetricData2",
        "com.sankuai.octo.statistic.domain.Metric2",
        "com.sankuai.octo.statistic.domain.Metrics",
        "com.sankuai.octo.statistic.model.StatSource",
        "com.sankuai.octo.statistic.model.PerfProtocolType",
        "com.meituan.mtrace.thrift.model.StatusCode",

      ]
    }
  }
}


custom {

#  bounded-mailbox {
#    mailbox-type = "akka.dispatch.NonBlockingBoundedMailbox"
#    mailbox-capacity = 2000
#  }


  daily-dispatcher {
    # Dispatcher is the name of the event-based dispatcher
    type = Dispatcher
    # What kind of ExecutionService to use
    executor = "fork-join-executor"
    # Configuration for the fork join pool
    fork-join-executor {
      # Min number of threads to cap factor-based parallelism number to
      parallelism-min = 4
      # The parallelism factor is used to determine thread pool size using the
      # following formula: ceil(available processors * factor). Resulting size
      # is then bounded by the parallelism-min and parallelism-max values.
      parallelism-factor = 3.0

      # Max number of threads to cap factor-based parallelism number to
      parallelism-max = 32

      # Setting to "FIFO" to use queue like peeking mode which "poll" or "LIFO" to use stack
      # like peeking mode which "pop".
      task-peeking-mode = "FIFO"
    }
    # Throughput defines the maximum number of messages to be
    # processed per actor before the thread jumps to the next actor.
    # Set to 1 for as fair as possible.
    throughput = 50
  }

  tag-dispatcher {
    # Dispatcher is the name of the event-based dispatcher
    type = Dispatcher
    # What kind of ExecutionService to use
    executor = "fork-join-executor"
    # Configuration for the fork join pool
    fork-join-executor {
      # Min number of threads to cap factor-based parallelism number to
      parallelism-min = 2
      # The parallelism factor is used to determine thread pool size using the
      # following formula: ceil(available processors * factor). Resulting size
      # is then bounded by the parallelism-min and parallelism-max values.
      parallelism-factor = 3.0

      # Max number of threads to cap factor-based parallelism number to
      parallelism-max = 8

      # Setting to "FIFO" to use queue like peeking mode which "poll" or "LIFO" to use stack
      # like peeking mode which "pop".
      task-peeking-mode = "FIFO"
    }
    # Throughput defines the maximum number of messages to be
    # processed per actor before the thread jumps to the next actor.
    # Set to 1 for as fair as possible.
    throughput = 50
  }

  group-dispatcher {
    # Dispatcher is the name of the event-based dispatcher
    type = Dispatcher
    # What kind of ExecutionService to use
    executor = "fork-join-executor"
    # Configuration for the fork join pool
    fork-join-executor {
      # Min number of threads to cap factor-based parallelism number to
      parallelism-min = 8
      # The parallelism factor is used to determine thread pool size using the
      # following formula: ceil(available processors * factor). Resulting size
      # is then bounded by the parallelism-min and parallelism-max values.
      parallelism-factor = 3.0

      # Max number of threads to cap factor-based parallelism number to
      parallelism-max = 64

      # Setting to "FIFO" to use queue like peeking mode which "poll" or "LIFO" to use stack
      # like peeking mode which "pop".
      task-peeking-mode = "FIFO"
    }
    # Throughput defines the maximum number of messages to be
    # processed per actor before the thread jumps to the next actor.
    # Set to 1 for as fair as possible.
    throughput = 50
  }

}
